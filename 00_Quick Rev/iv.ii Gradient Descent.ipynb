{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df96b0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(15000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c3ed66",
   "metadata": {},
   "source": [
    "# i. Gradient Descent\n",
    "\n",
    "Gradient Descent is a generic optimization algorithm capable of finding optimal solutions to a wide range of problems. The general idea of Gradient Descent is **to tweak parameters iteratively in order to minimize a cost function**.\n",
    "\n",
    "Suppose we are lost in the mountains in a dense fog, and we can only feel the slope of the ground below our feet. A good strategy to get to the bottom of the valley quickly is to go downhill in the direction of the steepest slope. This is exactly what **Gradient Descent** does: it **measures the local gradient of the error function with regard to the parameter vector θ, and it goes in the direction of descending gradient**. **Once the gradient is zero, we have reached a minimum!**\n",
    "\n",
    "Concretely, we start by filling θ with random values (this is called **random initialization**). Then we improve it  gradually, **taking one baby step at a time, each step attempting to decrease the cost function** (e.g., the MSE), **until the algorithm converges to a minimum**.\n",
    "\n",
    "\n",
    "<img src=\"./media/Screenshot (307).png\" width=\"800\" height=\"500\">\n",
    "\n",
    "**=>** In this depiction of Gradient Descent, the model parameters are initialized\n",
    "randomly and get tweaked repeatedly to minimize the cost function; **the learning step\n",
    "size is proportional to the slope of the cost function, so the steps gradually get smaller as\n",
    "the parameters approach the minimum**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3ecde",
   "metadata": {},
   "source": [
    "## i.i Learning Rate Hyperparameter \"η\"\n",
    "\n",
    "An important parameter in Gradient Descent is the **size of the steps**, **determined by the learning rate hyperparameter**. \n",
    "\n",
    "- If the learning rate is too small, then the algorithm will have to go through many iterations to converge, which will take a long time.\n",
    "\n",
    "<img src=\"./media/Screenshot (309).png\" width=\"800\" height=\"500\">\n",
    "\n",
    "\n",
    "- On the other hand, **if the learning rate is too high, we might jump across the valley and end up on the other side, possibly even higher up than we were before**. This might make the algorithm diverge, with larger and larger values, failing to find a good solution.\n",
    "\n",
    "<img src=\"./media/Screenshot (310).png\" width=\"800\" height=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1f606",
   "metadata": {},
   "source": [
    "# ii. Challenges faced in Gradient Descent\n",
    "\n",
    "Not all cost functions look like nice, regular bowls. There may be holes, ridges, plateaus, and all sorts of irregular terrains, that can make the convergence to the minimum difficult. \n",
    "\n",
    "The following figure shows the two main challenges with Gradient Descent.\n",
    "\n",
    "<img src=\"./media/Screenshot (312).png\" width=\"800\" height=\"500\">\n",
    "\n",
    "- If the random initialization starts the algorithm on the left, then it will converge to a local minimum, which is not as good as the global minimum.<br><br>\n",
    "\n",
    "- If it starts on the right, then it will take a very long time to cross the plateau. And if we stop too early, we'll never reach the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d60453",
   "metadata": {},
   "source": [
    "# iii. Why should be scale the features while implementing gradient descent?\n",
    "\n",
    "The MSE cost function for a Linear Regression model happens to be a convex function, which means that if we pick any two points on the curve, the line segment joining them never crosses the curve. This implies that there are no local minima, just one global minimum. It is also a continuous function with a slope that never changes abruptly.\n",
    "\n",
    "These two facts have a great consequence: **Gradient Descent is guaranteed to approach arbitrarily close the global minimum (if we wait long enough and if the learning rate is not too high)**.\n",
    "\n",
    "\n",
    "## iii.i Elongated Bowls leading to latency in covergence\n",
    "\n",
    "Although the cost function has the shape of a bowl, but (as demonstrated in the below figure) it **can be an elongated bowl if the features have very different scales**. \n",
    "\n",
    "<img src=\"./media/Screenshot (311).png\" width=\"800\" height=\"500\">\n",
    "\n",
    "Gradient Descent on a training set where features 1 and 2 have the same scale (on the left), and on a training set where feature 1 has much smaller values than feature 2 (on the right). \n",
    "\n",
    "**Since feature 1 is smaller, it takes a larger change in θ1 to affect the cost function, which is why the bowl is elongated along the θ1 axis.** Apparently, on the left the Gradient Descent algorithm goes straight toward the minimum, thereby reaching it quickly, whereas on the right it first goes in a direction almost orthogonal to the direction of the global minimum, and it ends with a long march down an almost flat valley. It will eventually reach the minimum, but it will\n",
    "take a long time.\n",
    "\n",
    "**That is exactly why when using Gradient Descent, we should ensure that all features have a similar scale (e.g., using Scikit-Learn’s StandardScaler class), or else it will take much longer to converge.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ee245",
   "metadata": {},
   "source": [
    "# iv. Training a model\n",
    "\n",
    "Training a model means **searching for a combination of model params that minimizes a cost function over the training set**.\n",
    "\n",
    "It's a search in the model's parameter space: **the more parameters a model has, the more dimensions this space has, and harder the search is**: searching for a needle in a 300-dimensional haystack is much trickier than in 3 dimensions.\n",
    "\n",
    "Fortunately, **since the cost function is convex in the case of Linear Regression, the needle is simply at the bottom of the bowl**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
